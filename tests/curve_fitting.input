# ###################################################
# author        : Jean Michel Sellier
# created       : 17 Mar. 2016, Cassibile (SR), Italy
# last modified : 18 Mar. 2016, Cassibile (SR), Italy
# purpose       :  The purpose of the following
#                  example is to fit a curve given by
#                  three points.
# ###################################################

# load a previously saved neural network
# LOAD_NEURAL_NETWORK

# total number of training data
# for supervised learning
NUMBER_OF_TRAINING_POINTS 3

# training data - input
TRAINING_POINT IN 0 0.15
TRAINING_POINT IN 1 0.60
TRAINING_POINT IN 2 0.80

# training data - output
TRAINING_POINT OUT 0 0.387298335
TRAINING_POINT OUT 1 0.774596669
TRAINING_POINT OUT 2 0.894427191

# space search for the weights
WEIGHT_MINIMUM -1
WEIGHT_MAXIMUM +1

# total number of neurons
NUMBER_OF_NEURONS 6

# define the number of connections/weights for every neuron
NEURON 0 NUMBER_OF_CONNECTIONS 1
NEURON 1 NUMBER_OF_CONNECTIONS 1
NEURON 2 NUMBER_OF_CONNECTIONS 1
NEURON 3 NUMBER_OF_CONNECTIONS 1
NEURON 4 NUMBER_OF_CONNECTIONS 1
NEURON 5 NUMBER_OF_CONNECTIONS 4

# define the activation function for every neuron
# neuron #0 does not need to be specified as it is an identity
# activation function by default
NEURON 1 ACTIVATION TANH
NEURON 2 ACTIVATION TANH
NEURON 3 ACTIVATION TANH
NEURON 4 ACTIVATION TANH
NEURON 5 ACTIVATION TANH

# define the discriminant function for every neuron
# neuron #0 does not need any discriminant as it is the identity function
NEURON 1 DISCRIMINANT LINEAR
NEURON 2 DISCRIMINANT LINEAR
NEURON 3 DISCRIMINANT LINEAR
NEURON 4 DISCRIMINANT LINEAR
NEURON 5 DISCRIMINANT LINEAR

# total number of layers for the network
NETWORK NUMBER_OF_LAYERS 3

# define the number of neurons for each layer
# in this specific case, the first (input) layer has 1 neurons,
# the (only) hidden layer has four layers
# the last (output) layer has only one neuron
NETWORK LAYER 0 NUMBER_OF_NEURONS 1
NETWORK LAYER 1 NUMBER_OF_NEURONS 4
NETWORK LAYER 2 NUMBER_OF_NEURONS 1

# assign neurons to every layer of the network
# syntax:
# NETWORK ASSIGN_NEURON_TO_LAYER layer_id local_neuron_id global_neuron_id
# first layer
NETWORK ASSIGN_NEURON_TO_LAYER 0 0 0
# second layer
NETWORK ASSIGN_NEURON_TO_LAYER 1 0 1
NETWORK ASSIGN_NEURON_TO_LAYER 1 1 2
NETWORK ASSIGN_NEURON_TO_LAYER 1 2 3
NETWORK ASSIGN_NEURON_TO_LAYER 1 3 4
# third layer
NETWORK ASSIGN_NEURON_TO_LAYER 2 0 5

# define the connections between neurons
# syntax: NEURON neuron_id1 CONNECTION connection_id neuron_id2
# neuron_id1 and neuron_id2 are the global indices of two neurons
# to be connected. the output of the neuron "neuron_id2" is connected
# to the input number "connection_id" of the neuron "neuron_id1"
# the first layer [0] does not need anything
# since its neurons are not connected to any neuron
NEURON 1 CONNECTION 0 0
NEURON 2 CONNECTION 0 0
NEURON 3 CONNECTION 0 0
NEURON 4 CONNECTION 0 0
NEURON 5 CONNECTION 0 1
NEURON 5 CONNECTION 1 2
NEURON 5 CONNECTION 2 3
NEURON 5 CONNECTION 3 4

# optimization method for the training process
# general syntax: TRAINING_METHOD method values

# simulated annealing syntax: verbosity mmax nmax kbtmin kbtmax accuracy
# where:
# verbosity = ON/OFF
# mmax      = outer loop - number of effective temperature steps
# nmax      = inner loop - number of test configurations
# kbtmin    = effective temperature minimum
# kbtmax    = effective temperature maximum
# accuracy  = numerical accuracy
TRAINING_METHOD SIMULATED_ANNEALING ON 25 25000 1.e-4 8.0 1.e-2

# random search syntax: verbosity nmax accuracy
# where:
# verbosity = ON/OFF
# nmax      = maximum number of random attempts
# accuracy  = numerical accuracy
# TRAINING_METHOD RANDOM_SEARCH ON 500 1.e-3

# gradient descent syntax: verbosity nxw maxiter gamma accuracy
# where:
# verbosity = ON/OFF
# nxw       = number of cells in one direction of the weight space
# maxiter   = maximum number of iterations
# gamma     = step size
# accuracy  = numerical accuracy
# TRAINING_METHOD GRADIENT_DESCENT ON 32 5000 0.01 1.e-6

# genetic algorithm syntax: verbosity nmax npop rate accuracy
# where:
# verbosity = ON/OFF
# nmax      = number of generations
# npop      = number of individuals per generation
# rate      = rate of change between one generation and the parent
# accuracy  = numerical accuracy
# TRAINING_METHOD GENETIC_ALGORITHM ON 2048 1024 0.1 1.e-4

# save the output of the network
# for now consider by default that neuron #0 is the input
# and neuron #(NUMBER_OF_NEURONS-1) is the output
SAVE_OUTPUT ON
OUTPUT_FILE_NAME final_results.dat
NUMBER_OF_POINTS 21
INPUT_POINT 0 0.0
INPUT_POINT 1 0.05
INPUT_POINT 2 0.10
INPUT_POINT 3 0.15
INPUT_POINT 4 0.20
INPUT_POINT 5 0.25
INPUT_POINT 6 0.30
INPUT_POINT 7 0.35
INPUT_POINT 8 0.40
INPUT_POINT 9 0.45
INPUT_POINT 10 0.50
INPUT_POINT 11 0.55
INPUT_POINT 12 0.60
INPUT_POINT 13 0.65
INPUT_POINT 14 0.70
INPUT_POINT 15 0.75
INPUT_POINT 16 0.80
INPUT_POINT 17 0.85
INPUT_POINT 18 0.90
INPUT_POINT 19 0.95
INPUT_POINT 20 1.0

# eventually save the neural network
# SAVE_NEURAL_NETWORK
